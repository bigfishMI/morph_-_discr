head(data)
# Create indexes for the 167 variables
colnames(data)
stock      <- match("Stock", colnames(data))
body.morph <- 2:38
oto.morph  <- 44:160
oto.meas   <- 39:43
misc.meas  <- 161:164
morph      <- c(body.morph,oto.meas,oto.morph)
all.meas   <- c(body.morph,oto.meas,oto.morph,misc.meas)
head(data[,oto.meas])
# Some quick checks
boxplot(data[,body.morph])
boxplot(data[,oto.morph])
boxplot(data[,oto.meas])
training.data <- data[1:dim(data)[1] %% 2 == 0, ]
dim(training.data)
#make the 'unknown' portion
test.data <- data[1:dim(data)[1] %% 2 != 0, ]
dim(test.data)
stepwise <- stepclass(Stock ~ .,
data = training.data[,c(morph, stock)],
method = "qda", direction = "both",
criterion = "AS",
improvement = 0.01,
start.vars = "TH04")
stepwise
names(stepwise)
stepwise$process
stepwise$result.pm
stepwise$formula
stepwise$model
step.vars <-  match(stepwise$model[,"name"], colnames(data))
#check the indexing
colnames(data)[step.vars]
source("normal functions.R")
# Normality tests on the chosen variables
par(mfrow = c(2,2))
norm.tests(data, step.vars)
#multivariate normality by stock
par(mfrow = c(1,1))
graph.mvn(data, step.vars)
graph.mvn.Stock(data, step.vars)
res <-chisq.plot((data[,step.vars]))
install.packages("rrcov")
library(rrcov)
library(rrcov)
library(mvoutlier)
res <-chisq.plot((data[,step.vars]))
dim(data)
data <- data[-res$outliers,]
dim(data)
graph.mvn(data, no.maturity)
graph.mvn(data, step.vars)
graph.mvn.Stock(data, step.vars)
# make training portion again
training.data <- data[1:dim(data)[1] %% 2 == 0, ]
dim(training.data)
#make the 'unknown' portion
test.data <- data[1:dim(data)[1] %% 2 != 0, ]
dim(test.data)
baseline.fit <- qda(Stock ~ ., data=training.data[,c(stock, step.vars)])
baseline.fit
names(baseline.fit)
class(baseline.fit)
baseline.predicted <- predict(baseline.fit, training.data[,step.vars])  # predict the stock of each fish using the fit
(baseline.predicted <- predict(baseline.fit, training.data[,step.vars]))  # predict the stock of each fish using the fit
names(baseline.predicted)
baseline.predicted$class
training.fit <- qda(Stock ~ ., data=training.data[,c(stock, step.vars)])
training.fit
names(training.fit)
class(training.fit)
training.predicted <- predict(training.fit, training.data[,step.vars])  # predict the stock of each fish using the fit
names(training.predicted)
training.predicted$class
data.data$Predicted.QDA <- training.predicted$class
data$Predicted.QDA <- training.predicted$class
training.predicted
ct <- table(baseline.data$Stock, baseline.predicted$class)
training.data$Predicted.QDA <- training.predicted$class
(ct <- table(training.data$Stock, training.predicted$class))
diag(prop.table(ct, 1))
# total percent correct
sum(diag(prop.table(ct)))
hist(baseline.predicted$posterior)
for(i in unique(baseline.predicted$class)) hist(baseline.predicted$posterior[baseline.predicted$class == i,i], main = i, xlab = "Posterior Probability")
for(i in unique(training.predicted$class)) {
hist(training.predicted$posterior[training.predicted$class == i,i],
main = i, xlab = "Posterior Probability")
}
test.predicted <- predict(training.fit, test.data[,step.vars])
test.predicted
class(test.predicted)
names(test.predicted)
test.predicted$class
training.fit2 <- QdaClassic(x=training.data[,step.vars], grouping=training.data$Stock)
training.predicted2 <- predict(training.fit2, training.data[,step.vars])
head(training.predicted2@x)
plotdat<-training.predicted2@x
plot(plotdat[,1], plotdat[,2], col = as.numeric(training.data$Stock))
plot(plotdat[,2], plotdat[,3], col = as.numeric(training.data$Stock))
as.numeric(training.data$Stock)
colnames(training.data)
training.data$Stock
class(training.data$Stock)
plot(plotdat[,1], plotdat[,2], col = 1:8)
plot(plotdat[,2], plotdat[,3], col = 1:8))
plot(plotdat[,2], plotdat[,3], col = 1:8)
plot(plotdat[,1], plotdat[,2], col = as.numeric(training.predicted2@classification))
plot(plotdat[,2], plotdat[,3], col = as.numeric(training.predicted2@classification))
library(scatterplot3d)
#install.packages("scatterplot3d")
install.packages("scatterplot3d")
library(scatterplot3d)
scatterplot3d(x = plotdat[,1], y = plotdat[,2], z = plotdat[,3],  main="training", highlight.3d=TRUE, pch = as.numeric(training.predicted2@classification))
install.packages("rgl")
library(rgl)
plot3d(x = plotdat[,1], y = plotdat[,2], z = plotdat[,3],  main="training",  col = as.numeric(training.predicted2@classification))
training.predicted2@ct
ct <- table(training.data$Stock, training.predicted2@classification)
diag(prop.table(ct, 1))
unique(training.data$Stock)
training.data$Stock[training.data$Stock == "S03 - ROSAMHIL"] <- "VIaS"
training.data$Stock[training.data$Stock == "S04 - DONEGAL"] <- "VIaS"
training.data$Stock[training.data$Stock == "X01A - BALTIC SEA"] <- "Outgroup"
training.data$Stock[training.data$Stock == "S01 - CELTIC SEA"] <- "Other"
training.data$Stock[training.data$Stock == "S02 - SW IRELAND"] <- "Other"
training.data$Stock[training.data$Stock == "S06 - IRISH SEA"] <- "Other"
training.data$Stock[training.data$Stock == "S10A - CAPE WRATH SPRING"] <- "VIaN"
training.data$Stock[training.data$Stock == "S10B - CAPE WRATH SUMMER"] <- "VIaN"
unique(training.data$Stock)
training.data$Stock <- as.factor(training.data$Stock)
training.fit2 <- QdaClassic(x=training.data[,step.vars], grouping=training.data$Stock)
training.predicted2 <- predict(training.fit2, training.data[,step.vars])
plotdat<-training.predicted2@x
plot3d(x = plotdat[,1], y = plotdat[,2], z = plotdat[,3],  main="training",  col = as.numeric(training.predicted2@classification))
plot3d(x = plotdat[,1],
y = plotdat[,2],
z = plotdat[,3],
main="training",
col = as.numeric(training.predicted2@classification),
pch = 3)
plot3d(x = plotdat[,1],
y = plotdat[,2],
z = plotdat[,3],
main="training",
col = as.numeric(training.predicted2@classification),
size = 3)
plot3d(x = plotdat[,1],
y = plotdat[,2],
z = plotdat[,3],
xlab = "QDA Axis 1",
ylab = "QDA Axis 2",
zlab = "QDA Axis 3",
main="training",
col = as.numeric(training.predicted2@classification),
size = 5)
training.fit2 <- LdaClassic(x=training.data[,step.vars], grouping=training.data$Stock)
training.predicted2 <- predict(training.fit2, training.data[,step.vars])
plotdat<-training.predicted2@x
plot3d(x = plotdat[,1],
y = plotdat[,2],
z = plotdat[,3],
xlab = "QDA Axis 1",
ylab = "QDA Axis 2",
zlab = "QDA Axis 3",
main="training",
col = as.numeric(training.predicted2@classification),
size = 5)
plot(training.predicted)
test.predicted$class
(ct <- table(test.data$Stock, test.predicted$class))
diag(prop.table(ct, 1))
# total percent correct
sum(diag(prop.table(ct)))
head(training.predicted2@x)
rm(list = ls())
dev.off()
library(MASS)
library(nortest)
library(klaR)
library(rrcov)
library(mvoutlier)
Iris <- data.frame(rbind(iris3[,,1], iris3[,,2], iris3[,,3]),
Sp = rep(c("s","c","v"), rep(50,3)))
Iris
plot(Iris$Petal.L., Iris$Petal.W., col = as.numeric(Iris$Sp))
#Assign a random half of Iris as the training data set
(train <- sample(1:150, 75))
table(Iris$Sp[train])
plot(Iris$Petal.L.[-train], Iris$Petal.W.[-train], col = "blue")
points(Iris$Petal.L.[train], Iris$Petal.W.[train], col = as.numeric(Iris$Sp[train]))
plot(Iris$Petal.L.[-train], Iris$Petal.W.[-train], col = "blue")
points(Iris$Petal.L.[train], Iris$Petal.W.[train], col = as.numeric(Iris$Sp[train]))
plot(Iris$Petal.L.[-train], Iris$Petal.W.[-train], col = "blue")
points(Iris$Petal.L.[train], Iris$Petal.W.[train], col = as.numeric(Iris$Sp[train]))
# Calculate the LDA and predict the missing species
(z <- lda(Sp ~ ., Iris, prior = c(1,1,1)/3, subset = train))
(x <- predict(z, Iris[-train, ])$class)
# Plot the results
plot(Iris$Petal.L.[-train], Iris$Petal.W.[-train], col = as.numeric(Iris$Sp[-train]))
points(Iris$Petal.L.[-train], Iris$Petal.W.[-train], col = as.numeric(x), pch = 4)
plot(Iris$Sepal.L.[-train], Iris$Sepal.W.[-train], col = as.numeric(Iris$Sp[-train]))
points(Iris$Sepal.L.[-train], Iris$Sepal.W.[-train], col = as.numeric(x), pch = 4)
data(iris)
iris
partimat(Species ~ ., data = iris, method = "lda")
partimat(Species ~ ., data = iris, method = "lda", plot.matrix = TRUE, imageplot = FALSE)
#Different types of analyses
# 1: Quadratic Discriminant Analyses (sensitive to non-normal data)
partimat(Species ~ ., data = iris, method = "qda")
# 2: regularized (supposed to be more robust against multicollinearity in the data)
partimat(Species ~ ., data = iris, method = "rda")
data     <- read.csv(file.path(".", "DA datasets", "Baseline_data_FINAL.csv"),sep=",", header=TRUE, stringsAsFactors=F)
dim(data)
head(data)
colnames(data)
stock      <- match("Stock", colnames(data))
body.morph <- 2:38
oto.morph  <- 44:160
oto.meas   <- 39:43
misc.meas  <- 161:164
morph      <- c(body.morph,oto.meas,oto.morph)
all.meas   <- c(body.morph,oto.meas,oto.morph,misc.meas)
head(data[,oto.meas])
boxplot(data[,body.morph])
boxplot(data[,oto.morph])
boxplot(data[,oto.meas])
# make training portion
training.data <- data[1:dim(data)[1] %% 2 == 0, ]
dim(training.data)
#make the 'unknown' portion
test.data <- data[1:dim(data)[1] %% 2 != 0, ]
dim(test.data)
stepwise <- stepclass(Stock ~ .,
data = training.data[,c(morph, stock)],
method = "qda", direction = "both",
criterion = "AS",
improvement = 0.01,
start.vars = "TH04")
stepwise
names(stepwise)
stepwise$process
stepwise$result.pm
stepwise$formula
stepwise$model
step.vars <-  match(stepwise$model[,"name"], colnames(data))
#check the indexing
colnames(data)[step.vars]
source("normal functions.R")
# Normality tests on the chosen variables
par(mfrow = c(2,2))
norm.tests(data, step.vars)
#multivariate normality by stock
par(mfrow = c(1,1))
graph.mvn(data, step.vars)
graph.mvn.Stock(data, step.vars)
#    check for and remove  outliers
res <-chisq.plot((data[,step.vars]))
dim(data)
data <- data[-res$outliers,]
dim(data)
par(mfrow = c(1,1))
graph.mvn(data, step.vars)
graph.mvn.Stock(data, step.vars)
# make training portion again
training.data <- data[1:dim(data)[1] %% 2 == 0, ]
dim(training.data)
#make the 'unknown' portion
test.data <- data[1:dim(data)[1] %% 2 != 0, ]
dim(test.data)
colnames(training.data)[c(stock, step.vars)]
training.data$Stock
training.fit <- lda(Stock ~ ., data=training.data[c(stock, step.vars)]) # fit the linear discriminant analysis to the training data, including the stock
training.fit
plot(training.fit, col = as.numeric(training.data$Stock))
training.predicted <- predict(training.fit, training.data[,step.vars])  # predict the stock of each fish using the fit
plot(training.predicted$x[,1],training.predicted$x[,2], col = as.numeric(training.data$Stock),main="training data", pch = as.numeric(training.data$Stock)) # make a scatterplot
as.factor(training.data$Stock)
training.data$Stock <- as.factor(training.data$Stock)
#linear DA
training.fit <- lda(Stock ~ ., data=training.data[c(stock, step.vars)]) # fit the linear discriminant analysis to the training data, including the stock
# Linear Discriminant Analysis with Jacknifed Prediction
#training.fit <- lda(Stock ~ ., data=training.data[,c(stock,step.vars)], CV=TRUE)
training.fit
training.predicted <- predict(training.fit, training.data[,step.vars])  # predict the stock of each fish using the fit
plot(training.predicted$x[,1],training.predicted$x[,2], col = as.numeric(training.data$Stock),main="training data", pch = as.numeric(training.data$Stock)) # make a scatterplot
legend("topright", col = as.numeric(unique(training.predicted$class)), pch = as.numeric(unique(training.predicted$class)), legend = substr(as.character(unique(training.predicted$class)),1,4))
plot(x$x[,1],x$x[,2], col = as.numeric(Iris$Sp),main="Predicted", pch = as.numeric(Iris$Sp)) # make a scatterplot
(z <- lda(Sp ~ ., Iris, prior = c(1,1,1)/3, subset = train))
(x <- predict(z, Iris[-train, ])$class)
x
dim(training.predicted$x)
names(training.predicted)
names(training.fit)
training.fit$svd
names(summary(training.fit))
ct <- table(training.data$Stock, training.predicted$class)
diag(prop.table(ct, 1))
# total percent correct
sum(diag(prop.table(ct)))
base.hist <- hist(apply(training.predicted$posterior, MARGIN=1, FUN=max),breaks=6, main = "LDA Posterior Probabilities", xlab = "Posterioir probability")
# remove previous datasets
rm(list = ls())
dev.off()
library(MASS)
library(nortest)
library(klaR)
library(rrcov)
library(mvoutlier)
# Simple example of Linear Discriminant Analysis
# Discriminant analysis uses a data set of known origin to classify unknown samples
#Make a random data set
Iris <- data.frame(rbind(iris3[,,1], iris3[,,2], iris3[,,3]),
Sp = rep(c("s","c","v"), rep(50,3)))
Iris
plot(Iris$Petal.L., Iris$Petal.W., col = as.numeric(Iris$Sp))
#Assign a random half of Iris as the training data set
(train <- sample(1:150, 75))
table(Iris$Sp[train])
plot(Iris$Petal.L.[-train], Iris$Petal.W.[-train], col = "blue")
points(Iris$Petal.L.[train], Iris$Petal.W.[train], col = as.numeric(Iris$Sp[train]))
# Calculate the LDA and predict the missing species
(z <- lda(Sp ~ ., Iris, prior = c(1,1,1)/3, subset = train))
(x <- predict(z, Iris[-train, ])$class)
x <- predict(z, Iris[-train, ])
plot(x$x[,1],x$x[,2],
col = as.numeric(Iris$Sp[-train]),
main="LDA of Iris",
pch = as.numeric(Iris$Sp[-train])) # make a scatterplot
(z <- lda(Sp ~ ., Iris, prior = c(1,1,1)/3, subset = train))
(x <- predict(z, Iris[-train, ])$class)
# Plot the results
plot(Iris$Petal.L.[-train], Iris$Petal.W.[-train], col = as.numeric(Iris$Sp[-train]))
points(Iris$Petal.L.[-train], Iris$Petal.W.[-train], col = as.numeric(x), pch = 4)
plot(Iris$Sepal.L.[-train], Iris$Sepal.W.[-train], col = as.numeric(Iris$Sp[-train]))
points(Iris$Sepal.L.[-train], Iris$Sepal.W.[-train], col = as.numeric(x), pch = 4)
(z <- lda(Sp ~ ., Iris, prior = c(1,1,1)/3, subset = train))
(x <- predict(z, Iris[-train, ]))
x$class
plot(x$x[,1],x$x[,2],
col = as.numeric(Iris$Sp[-train]),
main="LDA of Iris",
pch = as.numeric(Iris$Sp[-train]))
plot(Iris$Petal.L.[-train], Iris$Petal.W.[-train], col = as.numeric(Iris$Sp[-train]))
points(Iris$Petal.L.[-train], Iris$Petal.W.[-train], col = as.numeric(x), pch = 4)
plot(Iris$Petal.L.[-train], Iris$Petal.W.[-train], col = as.numeric(Iris$Sp[-train]))
points(Iris$Petal.L.[-train], Iris$Petal.W.[-train], col = as.numeric(x$class), pch = 4)
plot(Iris$Petal.L.[-train], Iris$Petal.W.[-train], col = as.numeric(Iris$Sp[-train]))
points(Iris$Petal.L.[-train], Iris$Petal.W.[-train], col = as.numeric(x$class), pch = 4)
plot(Iris$Petal.L.[-train], Iris$Petal.W.[-train], col = as.numeric(Iris$Sp[-train]))
points(Iris$Petal.L.[-train], Iris$Petal.W.[-train], col = as.numeric(x$class), pch = 4)
plot(Iris$Sepal.L.[-train], Iris$Sepal.W.[-train], col = as.numeric(Iris$Sp[-train]))
points(Iris$Sepal.L.[-train], Iris$Sepal.W.[-train], col = as.numeric(x$class), pch = 4)
data(iris)
iris
partimat(Species ~ ., data = iris, method = "lda")
rm(list = ls())
dev.off()
getwd()
library(Momocs)
library(jpeg)
getwd()
setwd(".\\Otolith photos BW")
# Get the list of otolith jpps
files <- list.files()
(files <- files[grep(".jpg", files, ignore.case = T)])
#plot a couple of images
img <- readJPEG(files[1])
plot(1:2, type='n')
rasterImage(img, 1.2, 1.27, 1.8, 1.73) #grayscale
img <- readJPEG(files[3])
plot(1:2, type='n')
rasterImage(img, 1.2, 1.27, 1.8, 1.73) #black and white
# Just plotting an image is not useful
# need the outline => use import_jpg() form the Momocs package
jpgs <- import_jpg(files)
class(jpgs)
length(jpgs)
head(jpgs[[1]])
plot(jpgs[[2]][,1], jpgs[[2]][,2])
plot(jpgs[[3]][,1], jpgs[[3]][,2])
# The import is just a list of coordinates
# So we convert it to a Momocs object called a "Coo" (Out, Opn)
oto <- Out(jpgs)
oto
names(oto)
panel(oto)
stack(oto)
oto <- coo_center(oto)
stack(oto)
# scale them
oto <- coo_scale(oto)
stack(oto)
# aligning, note this rotates AND FLIPS the otolith
oto <- coo_align(oto)
stack(oto)
# rotate by 180 degrees
oto <- coo_rotate(oto, theta = pi)
stack(oto)
#flip around x axis
oto <- coo_flipx(oto)
stack(oto)
#Perimieter
coo_perim(oto[1])
#No. of points
coo_nb(oto)
#remove 3 and 8
oto[3] <- NULL
coo_nb(oto)
oto[7] <- NULL
stack(oto)
#############################################################################
#
# Bigger, cleaner data set with otolith outlines processed externally
# Otoliths outlines traced and quality controlled in TPSDIG
#
# These are samples from spawning herring from two locations, one in Scotland one in Ireland
# The naming convention is Y-SXX-ZZZ.TPS
# Where Y = year (4 = 2004)
# s = Spawning sample
# XX = location (04 = Donegal, 10 = Cape Wrath)
# ZZZ = fish ID
#
############################################################################
setwd("..\\spawning Otolith TPS")
(files <- list.files())
(files <- files[grep(".tps", files, ignore.case = T)])
length(files)
y <- list()
for(j in files){
lines <- as.numeric(gsub("POINTS=", "", readLines(j)[3]))
tps <- read.table(j, skip = 3, nrows = lines, colClasses = "numeric", col.names = c("x", "Y"))
y[[j]]<- data.matrix(tps)
}
y
y[1]
head(y[1])
oto <- Out(y)
oto
panel(oto)
stack(oto, borders="#1A1A1A22", ldk=FALSE)
oto <- coo_center(oto) # center all the otoliths on the origin
oto <- coo_scale(oto) # scale them
oto <- coo_align(oto) # aligning
oto <- coo_rotate(oto, theta = pi) # rotate by 180 degrees
stack(oto, borders="#1A1A1A22", ldk=FALSE)
coo_plot(oto[1], lwd=2, col='#F2F2F2')
for(i in 1:15){
ef <- efourier(oto[1], i) # get the ith harmonic of elliptic fourier
efi <- efourier_i(ef) # get the inverse in order to plet it in the same frame
coo_draw(efi)
}
coo_plot(oto[1], lwd=2, col='#F2F2F2')
for(i in 1:15){
ef <- efourier(oto[1], i) # get the ith harmonic of elliptic fourier
efi <- efourier_i(ef) # get the inverse in order to plet it in the same frame
coo_draw(efi)
cat ("Press [enter] to continue")
line <- readline()
}
coo_plot(oto[1], lwd=1, col='#F2F2F2')
coo_draw(efourier_i(efourier(oto[1], nb.h = 30)), lwd = 2)
coo_plot(oto[1], lwd=1, col='#F2F2F2')
coo_draw(efourier_i(efourier(oto[1], nb.h = 30)), lwd = 2)
# Calculating the Elliptic Fourier Analysis (efourier) for the whole data set
efa<-efourier(oto, nb.h = 30, smooth.it = 0, norm = TRUE, start = FALSE) #start = False "does not define the first point of the outlines as an homologous point"
class(efa)
efa
# Performing a principal component analysis on the EFA
efa.pca <- PCA(efa)
efa.pca
plot(efa.pca, morpho=TRUE)
# Adding Factors
oto
names(oto)
(fact <- sapply(strsplit(names(oto), "-"), function(x)  x[2]))
class(fact)
oto$fac <- data.frame(Stock = fact)
oto
efa <- efourier(oto, nb.h = 30, smooth.it = 0, norm = TRUE, start = FALSE)
#PCA on the EFA
efa.pca <- PCA(efa)
efa.pca
plot(efa.pca, morpho=TRUE)
plot(efa.pca, 'Stock')
PCcontrib(efa.pca)
# What is the mean shape of otolith in each stock?
mshapes(efa) # the mean (global) shape
ms <- mshapes(efa, 'Stock')
ms$Coe
class(ms$Coe)
ms <- ms$shp
coo_plot(ms$S04A)
coo_draw(ms$S10A, border='forestgreen')
tps_grid(ms$S04A, ms$S10A) # deformation grid
tps_iso(ms$S04A, ms$S10A) # deformation iso
# A better example
data(bot)
botF <- efourier(bot, nb.h = 15)
x <- mshapes(botF, 'type', nb.pts=80)$shp
fr <- x$beer
to <- x$whisky
tps_arr(fr, to, arr.nb=200, palette=col_sari, amp=3)
oto.f <- efourier(oto, 30)
oto.p <- PCA(oto.f)
LDA(oto.p, 'Stock', retain=0.99) # retains 0.99 of the total variance
LDA(oto.p, 'Stock', retain=5) # retain 5 axis
oto.l <- LDA(oto.p, 'Stock', retain=0.99)
oto.l
plot(oto.l)
